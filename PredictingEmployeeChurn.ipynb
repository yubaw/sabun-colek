{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to HR Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction  evaluation  number_of_projects  average_montly_hours  \\\n",
      "0          0.38        0.53                   2                   157   \n",
      "1          0.80        0.86                   5                   262   \n",
      "2          0.11        0.88                   7                   272   \n",
      "3          0.72        0.87                   5                   223   \n",
      "4          0.37        0.52                   2                   159   \n",
      "\n",
      "   time_spend_company  work_accident  churn  promotion department  salary  \n",
      "0                   3              0      1          0      sales     low  \n",
      "1                   6              0      1          0      sales  medium  \n",
      "2                   4              0      1          0      sales  medium  \n",
      "3                   5              0      1          0      sales     low  \n",
      "4                   3              0      1          0      sales     low  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   satisfaction          14999 non-null  float64\n",
      " 1   evaluation            14999 non-null  float64\n",
      " 2   number_of_projects    14999 non-null  int64  \n",
      " 3   average_montly_hours  14999 non-null  int64  \n",
      " 4   time_spend_company    14999 non-null  int64  \n",
      " 5   work_accident         14999 non-null  int64  \n",
      " 6   churn                 14999 non-null  int64  \n",
      " 7   promotion             14999 non-null  int64  \n",
      " 8   department            14999 non-null  object \n",
      " 9   salary                14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Import pandas (as pd) to read the data\n",
    "import pandas as pd\n",
    "\n",
    "# Read \"turnover.csv\" and save it in a DataFrame called data\n",
    "data = pd.read_csv(r\"C:\\Users\\lenovo\\Downloads\\datacamp\\human-resources-analytics-predicting-employee-churn-in-python\\turnover.csv\")\n",
    "\n",
    "# Take a quick look to the first 5 rows of data\n",
    "print(data.head())\n",
    "\n",
    "# Get some information on the types of variables in data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values of the \"department\" column\n",
    "print(data.department.unique())\n",
    "\n",
    "# Print the unique values of the \"salary\" column\n",
    "print(data.salary.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the type of the \"salary\" column to categorical\n",
    "data.salary = data.salary.astype('category')\n",
    "\n",
    "# Provide the correct order of categories\n",
    "data.salary = data.salary.cat.reorder_categories(['low', 'medium', 'high'])\n",
    "\n",
    "# Encode categories\n",
    "data.salary = data.salary.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IT  RandD  accounting  hr  management  marketing  product_mng  sales  \\\n",
      "0   0      0           0   0           0          0            0      1   \n",
      "1   0      0           0   0           0          0            0      1   \n",
      "2   0      0           0   0           0          0            0      1   \n",
      "3   0      0           0   0           0          0            0      1   \n",
      "4   0      0           0   0           0          0            0      1   \n",
      "\n",
      "   support  technical  \n",
      "0        0          0  \n",
      "1        0          0  \n",
      "2        0          0  \n",
      "3        0          0  \n",
      "4        0          0  \n"
     ]
    }
   ],
   "source": [
    "# Get dummies and save them inside a new DataFrame\n",
    "departments = pd.get_dummies(data.department)\n",
    "\n",
    "# Take a quick look to the first 5 rows of the new DataFrame called departments\n",
    "print(departments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"accounting\" column to avoid \"dummy trap\"\n",
    "departments = departments.drop(\"accounting\", axis=1)\n",
    "\n",
    "# Drop the old column \"department\" as you don't need it anymore\n",
    "data = data.drop(\"department\", axis=1)\n",
    "\n",
    "# Join the new dataframe \"departments\" to your employee dataset: done\n",
    "data = data.join(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11428\n",
      "1     3571\n",
      "Name: churn, dtype: int64\n",
      "0    76.191746\n",
      "1    23.808254\n",
      "Name: churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use len() function to get the total number of observations and save it as the number of employees\n",
    "n_employees = len(data)\n",
    "\n",
    "# Print the number of employees who left/stayed\n",
    "print(data.churn.value_counts())\n",
    "\n",
    "# Print the percentage of employees who left/stayed\n",
    "print(data.churn.value_counts()/n_employees*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting employee turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target and features\n",
    "\n",
    "# Choose the dependent variable column (churn) and set it as target\n",
    "target = data.churn\n",
    "\n",
    "# Drop column churn and set everything else as features\n",
    "features = data.drop(\"churn\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function for splitting dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use that function to create the splits both for target and for features\n",
    "# Set the test sample to be 25% of your observations\n",
    "target_train, target_test, features_train, features_test = train_test_split(target,features,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of people who stayed/left\n",
    "stayed = 37\n",
    "left = 1138\n",
    "\n",
    "#sum of stayed and left\n",
    "total = stayed + left\n",
    "\n",
    "#gini index\n",
    "gini = 2*(stayed/total)*(left/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split by B!\n"
     ]
    }
   ],
   "source": [
    "# Gini index in case of splitting by variable A or B\n",
    "gini_A = 0.65\n",
    "gini_B = 0.15\n",
    "\n",
    "# check which Gini is lower and use it for spliting\n",
    "if gini_A < gini_B:\n",
    "    print(\"split by A!\")\n",
    "else:\n",
    "    print(\"split by B!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize it and call model by specifying the random_state parameter\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Apply a decision tree model to fit features to the target\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.22666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply a decision tree model to fit features to the target in the training set\n",
    "model.fit(features_train,target_train)\n",
    "\n",
    "# Check the accuracy score of the prediction for the training set\n",
    "model.score(features_train,target_train)*100\n",
    "\n",
    "# Check the accuracy score of the prediction for the test set\n",
    "model.score(features_test,target_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the graphical visualization export function\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Apply Decision Tree model to fit Features to the Target\n",
    "model.fit(features_train,target_train)\n",
    "\n",
    "# Export the tree to a dot file\n",
    "export_graphviz(model,\"tree.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the turnover prediction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.71535247577563\n",
      "97.06666666666666\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DecisionTreeClassifier while limiting the depth of the tree to 5\n",
    "model_depth_5 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_depth_5.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction for the training set\n",
    "print(model_depth_5.score(features_train,target_train)*100)\n",
    "\n",
    "# Print the accuracy of the prediction for the test set\n",
    "print(model_depth_5.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.57747355320473\n",
      "96.13333333333334\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DecisionTreeClassifier while limiting the sample size in leaves to 100\n",
    "model_sample_100 = DecisionTreeClassifier(min_samples_leaf=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_sample_100.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the training set\n",
    "print(model_sample_100.score(features_train,target_train)*100)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\n",
    "print(model_sample_100.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9240641711229947"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the function to calculate precision score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Predict whether employees will churn using the test set\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# Calculate precision score by comparing target_test with the prediction\n",
    "precision_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632107023411371"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the function to calculate recall score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Use the initial model to predict churn\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# Calculate recall score by comparing target_test with the prediction\n",
    "recall_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691623087590718"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the function to calculate ROC/AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Use initial model to predict churn (based on features_test)\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# Calculate ROC/AUC score by comparing target_test with the prediction\n",
    "roc_auc_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.70666666666668\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DecisionTreeClassifier \n",
    "model_depth_5_b = DecisionTreeClassifier(max_depth=5,class_weight=\"balanced\",random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_depth_5_b.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\n",
    "print(model_depth_5_b.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632107023411371\n",
      "0.9691623087590718\n",
      "0.9319955406911928\n",
      "0.959863876199084\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the recall score\n",
    "print(recall_score(target_test,prediction))\n",
    "# Print the ROC/AUC score\n",
    "print(roc_auc_score(target_test,prediction))\n",
    "\n",
    "# Initialize the model\n",
    "model_depth_7_b = DecisionTreeClassifier(max_depth=7,class_weight=\"balanced\",random_state=42)\n",
    "# Fit it to the training component\n",
    "model_depth_7_b.fit(features_train,target_train)\n",
    "# Make prediction using test component\n",
    "prediction_b = model_depth_7_b.predict(features_test)\n",
    "# Print the recall score for the balanced model\n",
    "print(recall_score(target_test,prediction_b))\n",
    "# Print the ROC/AUC score for the balanced model\n",
    "print(print(roc_auc_score(target_test,prediction_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the best turnover prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98533333 0.98533333 0.974      0.96533333 0.96       0.97933333\n",
      " 0.99       0.99333333 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Import the function for implementing cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use that function to print the cross validation score for 10 folds\n",
    "print(cross_val_score(model,features,target,cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate values for maximum depth\n",
    "depth = [i for i in range(5,21,1)]\n",
    "\n",
    "# Generate values for minimum sample size\n",
    "samples = [i for i in range(50,500,50)]\n",
    "\n",
    "# Create the dictionary with parameters to be checked\n",
    "parameters = dict(max_depth=depth, min_samples_leaf=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "# import the GridSearchCV function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up parameters: done\n",
    "parameters = dict(max_depth=depth, min_samples_leaf=samples)\n",
    "\n",
    "# initialize the param_search function using the GridSearchCV function, initial model and parameters above\n",
    "param_search = GridSearchCV(model, parameters)\n",
    "\n",
    "# fit the param_search to the training dataset\n",
    "param_search.fit(features_train, target_train)\n",
    "\n",
    "# print the best parameters found\n",
    "print(param_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction</th>\n",
       "      <td>0.453971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>0.397473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluation</th>\n",
       "      <td>0.104644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>0.033545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_projects</th>\n",
       "      <td>0.007103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical</th>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_accident</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_mng</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "satisfaction            0.453971\n",
       "time_spend_company      0.397473\n",
       "evaluation              0.104644\n",
       "average_montly_hours    0.033545\n",
       "number_of_projects      0.007103\n",
       "technical               0.002226\n",
       "hr                      0.001038\n",
       "promotion               0.000000\n",
       "salary                  0.000000\n",
       "work_accident           0.000000\n",
       "RandD                   0.000000\n",
       "management              0.000000\n",
       "marketing               0.000000\n",
       "product_mng             0.000000\n",
       "sales                   0.000000\n",
       "support                 0.000000\n",
       "IT                      0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = DecisionTreeClassifier(max_depth=5, min_samples_leaf=50, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "model_best.fit(features_train, target_train)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_importances = model_best.feature_importances_\n",
    "\n",
    "# Create a list of features: done\n",
    "feature_list = list(features)\n",
    "\n",
    "# Save the results inside a DataFrame using feature_list as an index\n",
    "relative_importances = pd.DataFrame(index=feature_list, data=feature_importances, columns=[\"importance\"])\n",
    "\n",
    "# Sort values to learn most important features\n",
    "relative_importances.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only features with relative importance higher than 1%\n",
    "selected_features = relative_importances[relative_importances.importance>0.01]\n",
    "\n",
    "# create a list from those features: done\n",
    "selected_list = selected_features.index\n",
    "\n",
    "# transform both features_train and features_test components to include only selected features\n",
    "features_train_selected = features_train[selected_list]\n",
    "features_test_selected = features_test[selected_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.61333333333334\n",
      "90.96989966555184\n",
      "93.36437499926731\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best model using parameters provided in description\n",
    "model_best = DecisionTreeClassifier(max_depth=8, min_samples_leaf=150, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Fit the model using only selected features from training set: done\n",
    "model_best.fit(features_train_selected, target_train)\n",
    "\n",
    "# Make prediction based on selected list of features from test set\n",
    "prediction_best = model_best.predict(features_test_selected)\n",
    "\n",
    "# Print the general accuracy of the model_best\n",
    "print(model_best.score(features_test_selected, target_test) * 100)\n",
    "\n",
    "# Print the recall score of the model predictions\n",
    "print(recall_score(target_test, prediction_best) * 100)\n",
    "\n",
    "# Print the ROC/AUC score of the model predictions\n",
    "print(roc_auc_score(target_test, prediction_best) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
